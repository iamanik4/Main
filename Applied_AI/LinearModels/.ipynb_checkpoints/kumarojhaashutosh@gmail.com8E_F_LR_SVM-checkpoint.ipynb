{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HExLQrE4ZxR"
   },
   "source": [
    "<h1><font color='blue'> 9E and 9F: Finding the Probability P(Y==1|X)</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LuKrFzC4ZxV"
   },
   "source": [
    "<h2><font color='Geen'> 9E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wES-wWN4ZxX"
   },
   "source": [
    "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
    "\n",
    "Check the documentation for better understanding of these attributes: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
    "\n",
    "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
    "\n",
    "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
    "\n",
    "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
    "\n",
    "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
    "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
    "\n",
    "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
    "\n",
    "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z830CfMk4Zxa"
   },
   "source": [
    "## Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuBxHiCQ4Zxc"
   },
   "source": [
    "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
    "\n",
    "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
    "\n",
    "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 5) (3200,)\n",
      "(800, 5) (800,)\n",
      "(1000, 5) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=24)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHie1zqH4Zxt"
   },
   "source": [
    "### Pseudo code\n",
    "\n",
    "clf = SVC(gamma=0.001, C=100.)<br>\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
    "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
    "    \n",
    "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
    "\n",
    "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can write your code here\n",
    "gamma = 0.001\n",
    "clf = SVC(gamma=gamma, C=100)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(xq):\n",
    "    val = 0\n",
    "    for alpha,xi in zip(clf.dual_coef_[0],clf.support_vectors_): #the dual_coef_[i] contains label[i]*alpha[i]\n",
    "        val += alpha*np.exp(-gamma*np.linalg.norm(xi-xq)**2) \n",
    "    return val+clf.intercept_.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_fun(X_val):\n",
    "    fcv = []\n",
    "    for xq in X_val:\n",
    "        fcv.append(K(xq))\n",
    "    return(np.array(fcv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.69065026, -4.01123357, -2.48966713,  1.35046624, -2.59528514])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_fun(X_val)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.69065026, -4.01123357, -2.48966713,  1.35046624, -2.59528514])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function(X_val)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the custom function gives same values as the inbuilt decision function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0bKCboN4Zxu"
   },
   "source": [
    "<h2><font color='Geen'> 9F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMn7OEN94Zxw"
   },
   "source": [
    "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
    "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0n5EFkx4Zxz"
   },
   "source": [
    "## TASK F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0HOqVJq4Zx1"
   },
   "source": [
    "\n",
    "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
    "\n",
    "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
    "\n",
    "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
    "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
    "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
    "\n",
    "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTY7z2bd4Zx2"
   },
   "source": [
    "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] [550 250]\n"
     ]
    }
   ],
   "source": [
    "fcv = dec_fun(X_val)\n",
    "y_val_cpy = y_val.astype('float')\n",
    "unique,counts = np.unique(y_val_cpy,return_counts=True)\n",
    "print(unique,counts)\n",
    "y_val_cpy[y_val_cpy==unique[0]]=1.0/(counts[0]+2)\n",
    "y_val_cpy[y_val_cpy==unique[1]]=(counts[1]+1.0)/(counts[1]+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w,x,b):\n",
    "    return 1/(1+np.exp(-(w@x+b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(X,y,w,b,lamda,alpha,N):\n",
    "    w_new = (1-alpha*lamda/N)*w + alpha*X*(y-sigmoid(w,X.T,b))\n",
    "    b_new = b + alpha*(y-sigmoid(w,X.T,b))\n",
    "    return w_new,b_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X, y, batchSize):\n",
    "    # loop over our dataset `X` in mini-batches of size `batchSize`\n",
    "    for i in np.arange(0, X.shape[0], batchSize):\n",
    "        # yield a tuple of the current batched data and labels\n",
    "        yield (X[i:i + batchSize], y[i:i + batchSize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_loss(A,n):# your code\n",
    "    loss=0\n",
    "    for Y in A:\n",
    "        loss += Y[0]*math.log(Y[1])+(1-Y[0])*math.log(1-Y[1]) \n",
    "    loss = -loss/n\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros((1,))\n",
    "b = 0\n",
    "lamda  = 0.0001\n",
    "alpha = 0.0001\n",
    "N = len(fcv)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:1\n",
      "Training Loss:0.6552991440625178\n",
      "Test Loss:0.6216799191875771\n",
      "===========================================================================\n",
      "iteration:2\n",
      "Training Loss:0.5899504093091643\n",
      "Test Loss:0.5645912433935767\n",
      "===========================================================================\n",
      "iteration:3\n",
      "Training Loss:0.5376450468017597\n",
      "Test Loss:0.5185955466686065\n",
      "===========================================================================\n",
      "iteration:4\n",
      "Training Loss:0.4953452949234486\n",
      "Test Loss:0.4811179312138139\n",
      "===========================================================================\n",
      "iteration:5\n",
      "Training Loss:0.4607177842269182\n",
      "Test Loss:0.4502053772357796\n",
      "===========================================================================\n",
      "iteration:6\n",
      "Training Loss:0.43201116620223556\n",
      "Test Loss:0.4243957071932323\n",
      "===========================================================================\n",
      "iteration:7\n",
      "Training Loss:0.40792005329857134\n",
      "Test Loss:0.40259569163253994\n",
      "===========================================================================\n",
      "iteration:8\n",
      "Training Loss:0.38746914857339987\n",
      "Test Loss:0.3839836238254411\n",
      "===========================================================================\n",
      "iteration:9\n",
      "Training Loss:0.3699243012691913\n",
      "Test Loss:0.3679364008743245\n",
      "===========================================================================\n",
      "iteration:10\n",
      "Training Loss:0.35472727885274635\n",
      "Test Loss:0.3539765039079248\n",
      "===========================================================================\n",
      "iteration:11\n",
      "Training Loss:0.34144882027064943\n",
      "Test Loss:0.3417338531083492\n",
      "===========================================================================\n",
      "iteration:12\n",
      "Training Loss:0.32975501183164174\n",
      "Test Loss:0.3309183847754427\n",
      "===========================================================================\n",
      "iteration:13\n",
      "Training Loss:0.31938314266484286\n",
      "Test Loss:0.3213002439334413\n",
      "===========================================================================\n",
      "iteration:14\n",
      "Training Loss:0.31012425112115755\n",
      "Test Loss:0.31269536737583653\n",
      "===========================================================================\n",
      "iteration:15\n",
      "Training Loss:0.30181039569982493\n",
      "Test Loss:0.3049548927351467\n",
      "===========================================================================\n",
      "iteration:16\n",
      "Training Loss:0.29430527895800895\n",
      "Test Loss:0.2979573002257887\n",
      "===========================================================================\n",
      "iteration:17\n",
      "Training Loss:0.2874972693182899\n",
      "Test Loss:0.29160252219300625\n",
      "===========================================================================\n",
      "iteration:18\n",
      "Training Loss:0.2812941533109972\n",
      "Test Loss:0.2858074827676511\n",
      "===========================================================================\n",
      "iteration:19\n",
      "Training Loss:0.2756191487461773\n",
      "Test Loss:0.28050268691278957\n",
      "===========================================================================\n",
      "iteration:20\n",
      "Training Loss:0.27040784585353755\n",
      "Test Loss:0.27562958702863327\n",
      "===========================================================================\n",
      "iteration:21\n",
      "Training Loss:0.26560583812342137\n",
      "Test Loss:0.27113853126412746\n",
      "===========================================================================\n",
      "iteration:22\n",
      "Training Loss:0.2611668707347844\n",
      "Test Loss:0.26698715111215393\n",
      "===========================================================================\n",
      "iteration:23\n",
      "Training Loss:0.25705138105688347\n",
      "Test Loss:0.26313908375226086\n",
      "===========================================================================\n",
      "iteration:24\n",
      "Training Loss:0.2532253388312813\n",
      "Test Loss:0.25956295170834337\n",
      "===========================================================================\n",
      "iteration:25\n",
      "Training Loss:0.24965931739417382\n",
      "Test Loss:0.2562315419516265\n",
      "===========================================================================\n",
      "iteration:26\n",
      "Training Loss:0.24632774449024541\n",
      "Test Loss:0.25312114082534004\n",
      "===========================================================================\n",
      "iteration:27\n",
      "Training Loss:0.2432082937828996\n",
      "Test Loss:0.2502109916324353\n",
      "===========================================================================\n",
      "iteration:28\n",
      "Training Loss:0.24028138741329827\n",
      "Test Loss:0.24748284948063623\n",
      "===========================================================================\n",
      "iteration:29\n",
      "Training Loss:0.23752978683073997\n",
      "Test Loss:0.24492061377030055\n",
      "===========================================================================\n",
      "Final Weights:\n",
      "[0.90106319]\n",
      "Final Intercept: [-0.1014738]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "lossHistoryTrain = []\n",
    "lossHistoryTest = []\n",
    "epochs = range(1,30)\n",
    "for epoch in epochs:\n",
    "    # initialize the total loss for the epoch\n",
    "    epochLossTrain = []\n",
    "    epochLossTest = []\n",
    "    # loop over our data in batches\n",
    "    for (batchX, batchY) in next_batch(fcv, y_val_cpy, 1):\n",
    "        preds = sigmoid(w,batchX,b)\n",
    "        loss = -(batchY*math.log(preds)+(1-batchY)*math.log(1-preds))\n",
    "        epochLossTrain.append(loss)\n",
    "        w, b = update_weights(batchX,batchY,w,b,lamda,alpha,N)\n",
    "        \n",
    "    avgLossTrain = np.average(epochLossTrain)\n",
    "    lossHistoryTrain.append(avgLossTrain)\n",
    "    print(\"iteration:{}\".format(epoch))\n",
    "    print(\"Training Loss:{}\".format(avgLossTrain))\n",
    "    y_pred = [sigmoid(w,x.reshape(-1,1),b) for x in dec_fun(X_test)]\n",
    "    avgLossTest = compute_log_loss(zip(y_test,y_pred),len(y_test))\n",
    "    lossHistoryTest.append(avgLossTest)\n",
    "    print(\"Test Loss:{}\".format(avgLossTest))\n",
    "    print('='*75)\n",
    "print('Final Weights:')\n",
    "print(w)\n",
    "print('Final Intercept:',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs,lossHistoryTrain)\n",
    "plt.plot(epochs,lossHistoryTest)\n",
    "plt.legend(['train loss','test loss'])\n",
    "plt.title('Loss vs epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CM3odN1Z4Zx3"
   },
   "source": [
    "\n",
    "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
    "\n",
    "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
    "\n",
    "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
    "\n",
    "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
    "\n",
    "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8E&F_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
